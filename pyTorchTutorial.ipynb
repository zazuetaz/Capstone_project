{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyTorchTutorial",
      "provenance": [],
      "collapsed_sections": [
        "FgIZ7DYwt8wG",
        "-CZqQ8Hzt_Z7",
        "VC1xm86PqrQO",
        "BtaKaZRTuslw",
        "hMsHX3_kzwi2",
        "74cxjinJv426",
        "Dkxx7b0d3uik"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zazuetaz/Capstone_project/blob/master/pyTorchTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v27ALuMYh0KI",
        "colab_type": "text"
      },
      "source": [
        "# Objectives\n",
        "You will be able to \n",
        "* Translate a Neural Network from Keras to PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPa0arksb71B",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch vs Keras\n",
        "## Pros \n",
        "Keras \n",
        "* easy to code \n",
        "* less code \n",
        "* great documentation\n",
        "* been used longer \n",
        "* easy for new comers\n",
        "\n",
        "PyTorch\n",
        "* more flexible\n",
        "* dynamic graphs - more pythonic (doesn't compile)\n",
        "* great for research and debugging algorithm\n",
        "* easier on memory\n",
        "\n",
        "## Cons\n",
        "Keras\n",
        "* compiles models (static graphs) \n",
        "* hard to debug specific parts of your model\n",
        "* hard for research\n",
        "* heavier on memory \n",
        "\n",
        "## PyTorch\n",
        "* hard for new comers\n",
        "* write your own training loops\n",
        "* you have to know about deep learning to use it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blWuc1Cjhgt1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4409e83a-3a48-4f83-9bbf-9bfd56d0b17b"
      },
      "source": [
        "# Load in libraries\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense \n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.optimizers import Adam \n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmQ2ZH4Xhz1M",
        "colab_type": "text"
      },
      "source": [
        "# Load in Iris Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXj6WnpshvlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()\n",
        "data = iris.data \n",
        "target = iris.target\n",
        "columns = iris.feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkjNIwdPidy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "abfe629e-a20f-4513-b057-83ab59453a62"
      },
      "source": [
        "df = pd.DataFrame(data, columns=columns)\n",
        "df['target'] = target \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2       0\n",
              "1                4.9               3.0  ...               0.2       0\n",
              "2                4.7               3.2  ...               0.2       0\n",
              "3                4.6               3.1  ...               0.2       0\n",
              "4                5.0               3.6  ...               0.2       0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeDRIbhfilQm",
        "colab_type": "text"
      },
      "source": [
        "# Build a single layer perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xcm6B9iiiXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(input_dim=4, units=8, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkuUspnmjETY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "93ccb9dc-ea3c-4617-e471-9fbe78812bcb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 67\n",
            "Trainable params: 67\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wgDLrcslBS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qroi4nblL6v",
        "colab_type": "text"
      },
      "source": [
        "# Split Data into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkAnL9kWlJxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.15)\n",
        "X_train, y_train = df_train.drop(columns=['target']), df_train['target']\n",
        "X_test, y_test = df_test.drop(columns=['target']), df_test['target']\n",
        "y_train_dummies = pd.get_dummies(y_train)\n",
        "y_test_dummies = pd.get_dummies(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-sj2P-EliYc",
        "colab_type": "text"
      },
      "source": [
        "# Fit the Keras Model and Evaluate it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6h3b3xIlcD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21bf9c11-3caa-40f1-9a4e-29b40c41191f"
      },
      "source": [
        "%timeit\n",
        "model.fit(X_train, y_train_dummies, epochs=50, batch_size=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 8.58 µs\n",
            "Epoch 1/50\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 5.1271\n",
            "Epoch 2/50\n",
            "127/127 [==============================] - 0s 190us/step - loss: 4.9922\n",
            "Epoch 3/50\n",
            "127/127 [==============================] - 0s 131us/step - loss: 4.8582\n",
            "Epoch 4/50\n",
            "127/127 [==============================] - 0s 107us/step - loss: 4.7251\n",
            "Epoch 5/50\n",
            "127/127 [==============================] - 0s 114us/step - loss: 4.5989\n",
            "Epoch 6/50\n",
            "127/127 [==============================] - 0s 111us/step - loss: 4.4692\n",
            "Epoch 7/50\n",
            "127/127 [==============================] - 0s 109us/step - loss: 4.3408\n",
            "Epoch 8/50\n",
            "127/127 [==============================] - 0s 112us/step - loss: 4.2182\n",
            "Epoch 9/50\n",
            "127/127 [==============================] - 0s 121us/step - loss: 4.0953\n",
            "Epoch 10/50\n",
            "127/127 [==============================] - 0s 117us/step - loss: 3.9772\n",
            "Epoch 11/50\n",
            "127/127 [==============================] - 0s 102us/step - loss: 3.8529\n",
            "Epoch 12/50\n",
            "127/127 [==============================] - 0s 128us/step - loss: 3.7341\n",
            "Epoch 13/50\n",
            "127/127 [==============================] - 0s 137us/step - loss: 3.6103\n",
            "Epoch 14/50\n",
            "127/127 [==============================] - 0s 103us/step - loss: 3.4923\n",
            "Epoch 15/50\n",
            "127/127 [==============================] - 0s 168us/step - loss: 3.3628\n",
            "Epoch 16/50\n",
            "127/127 [==============================] - 0s 169us/step - loss: 3.2353\n",
            "Epoch 17/50\n",
            "127/127 [==============================] - 0s 119us/step - loss: 3.0984\n",
            "Epoch 18/50\n",
            "127/127 [==============================] - 0s 115us/step - loss: 2.9603\n",
            "Epoch 19/50\n",
            "127/127 [==============================] - 0s 115us/step - loss: 2.8275\n",
            "Epoch 20/50\n",
            "127/127 [==============================] - 0s 114us/step - loss: 2.6854\n",
            "Epoch 21/50\n",
            "127/127 [==============================] - 0s 116us/step - loss: 2.5592\n",
            "Epoch 22/50\n",
            "127/127 [==============================] - 0s 118us/step - loss: 2.4268\n",
            "Epoch 23/50\n",
            "127/127 [==============================] - 0s 121us/step - loss: 2.3104\n",
            "Epoch 24/50\n",
            "127/127 [==============================] - 0s 117us/step - loss: 2.2058\n",
            "Epoch 25/50\n",
            "127/127 [==============================] - 0s 135us/step - loss: 2.0985\n",
            "Epoch 26/50\n",
            "127/127 [==============================] - 0s 162us/step - loss: 2.0075\n",
            "Epoch 27/50\n",
            "127/127 [==============================] - 0s 263us/step - loss: 1.9178\n",
            "Epoch 28/50\n",
            "127/127 [==============================] - 0s 115us/step - loss: 1.8412\n",
            "Epoch 29/50\n",
            "127/127 [==============================] - 0s 126us/step - loss: 1.7688\n",
            "Epoch 30/50\n",
            "127/127 [==============================] - 0s 130us/step - loss: 1.7017\n",
            "Epoch 31/50\n",
            "127/127 [==============================] - 0s 123us/step - loss: 1.6410\n",
            "Epoch 32/50\n",
            "127/127 [==============================] - 0s 125us/step - loss: 1.5856\n",
            "Epoch 33/50\n",
            "127/127 [==============================] - 0s 113us/step - loss: 1.5310\n",
            "Epoch 34/50\n",
            "127/127 [==============================] - 0s 133us/step - loss: 1.4797\n",
            "Epoch 35/50\n",
            "127/127 [==============================] - 0s 140us/step - loss: 1.4295\n",
            "Epoch 36/50\n",
            "127/127 [==============================] - 0s 120us/step - loss: 1.3868\n",
            "Epoch 37/50\n",
            "127/127 [==============================] - 0s 112us/step - loss: 1.3426\n",
            "Epoch 38/50\n",
            "127/127 [==============================] - 0s 124us/step - loss: 1.2995\n",
            "Epoch 39/50\n",
            "127/127 [==============================] - 0s 127us/step - loss: 1.2561\n",
            "Epoch 40/50\n",
            "127/127 [==============================] - 0s 125us/step - loss: 1.2199\n",
            "Epoch 41/50\n",
            "127/127 [==============================] - 0s 123us/step - loss: 1.1819\n",
            "Epoch 42/50\n",
            "127/127 [==============================] - 0s 121us/step - loss: 1.1429\n",
            "Epoch 43/50\n",
            "127/127 [==============================] - 0s 169us/step - loss: 1.1089\n",
            "Epoch 44/50\n",
            "127/127 [==============================] - 0s 128us/step - loss: 1.0774\n",
            "Epoch 45/50\n",
            "127/127 [==============================] - 0s 136us/step - loss: 1.0458\n",
            "Epoch 46/50\n",
            "127/127 [==============================] - 0s 125us/step - loss: 1.0142\n",
            "Epoch 47/50\n",
            "127/127 [==============================] - 0s 122us/step - loss: 0.9881\n",
            "Epoch 48/50\n",
            "127/127 [==============================] - 0s 119us/step - loss: 0.9622\n",
            "Epoch 49/50\n",
            "127/127 [==============================] - 0s 128us/step - loss: 0.9365\n",
            "Epoch 50/50\n",
            "127/127 [==============================] - 0s 127us/step - loss: 0.9150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f559b027198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqiyUW7slb-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_preds = model.predict_classes(X_train)\n",
        "y_test_preds = model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF9mvLZ3ndd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94e0c6d0-343c-48fd-cdd7-4d00d5b6250e"
      },
      "source": [
        "accuracy_score(y_train, y_train_preds), accuracy_score(y_test, y_test_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6614173228346457, 0.6956521739130435)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZu_on3oVs-",
        "colab_type": "text"
      },
      "source": [
        "# Replicating this in PyTorch\n",
        "* import necessary libraries\n",
        "* build model architecture\n",
        "* define loss function\n",
        "* train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0GhZUWyoLTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F  \n",
        "\n",
        "import torchsummary\n",
        "from torch.autograd import Variable \n",
        "from torch.optim import Adam as Adam_torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgIZ7DYwt8wG",
        "colab_type": "text"
      },
      "source": [
        "## Build Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLborXk7pplP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch_model = nn.Sequential(\n",
        "    nn.Linear(4,  8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 3),\n",
        "    nn.Softmax(dim=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pv4zuZRpxIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "358fac0d-90a3-4073-bf7a-413d1f377496"
      },
      "source": [
        "# Notice we can see our weights here\n",
        "weights = list(torch_model.parameters())\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.4179,  0.0135,  0.0296, -0.1518],\n",
              "         [ 0.3872, -0.1206, -0.4764,  0.3640],\n",
              "         [-0.0504,  0.3720, -0.3487,  0.2162],\n",
              "         [-0.0890,  0.4887,  0.2884,  0.3531],\n",
              "         [-0.0863,  0.2321,  0.3914, -0.3927],\n",
              "         [ 0.1562,  0.2368, -0.1866,  0.2092],\n",
              "         [-0.2788,  0.3466, -0.1761,  0.0908],\n",
              "         [ 0.0889,  0.4292, -0.4459,  0.1175]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3588, -0.1922, -0.1841, -0.3577,  0.4194, -0.0551, -0.2723, -0.4355],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0824, -0.0930, -0.0353,  0.2544, -0.0875, -0.2417, -0.0550, -0.2578],\n",
              "         [-0.0805, -0.0113,  0.1739,  0.1341,  0.0944, -0.0948, -0.3415,  0.1262],\n",
              "         [-0.0433,  0.1298, -0.1252, -0.0362,  0.0518, -0.2474, -0.3164, -0.2150]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0196,  0.3166, -0.1459], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CZqQ8Hzt_Z7",
        "colab_type": "text"
      },
      "source": [
        "## Define loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGbtAs7puDUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch_loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC1xm86PqrQO",
        "colab_type": "text"
      },
      "source": [
        "## Before we fit our model to our data we have to convert our data to PyTorch Tensors\n",
        "* This seems a bit extraneous but this is part of what makes PyTorch so fast and perform so well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnDmxz5npx5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tensor = torch.tensor(X_train.values, requires_grad=True)\n",
        "X_test_tensor = torch.tensor(X_test.values, requires_grad=True)\n",
        " # notice we're not using the dummy labels\n",
        "y_train_tensor = torch.tensor(y_train.values)\n",
        "y_test_tensor = torch.tensor(y_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtaKaZRTuslw",
        "colab_type": "text"
      },
      "source": [
        "### Let's test that our model can take our training data and return a prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCPCvTutuzDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74da1c17-f9f6-4bea-97e1-3b82e86373a1"
      },
      "source": [
        "torch_model(X_train_tensor.float())[:10] # first 10 y_preds of our model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2932, 0.5164, 0.1904],\n",
              "        [0.3262, 0.5256, 0.1483],\n",
              "        [0.2296, 0.5786, 0.1918],\n",
              "        [0.3007, 0.5179, 0.1813],\n",
              "        [0.2090, 0.6143, 0.1767],\n",
              "        [0.3029, 0.5192, 0.1780],\n",
              "        [0.3088, 0.5193, 0.1720],\n",
              "        [0.3193, 0.5234, 0.1574],\n",
              "        [0.3172, 0.5263, 0.1565],\n",
              "        [0.2933, 0.5110, 0.1957]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMsHX3_kzwi2",
        "colab_type": "text"
      },
      "source": [
        "### Setup your optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om_-Opclz0Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the optimizer takes in the parameters of your model as inputs to update them\n",
        "# We'll leave the other parameters to their default value\n",
        "optimizer = Adam_torch(torch_model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74cxjinJv426",
        "colab_type": "text"
      },
      "source": [
        "## Let's go through one iteration of training and then convert that to a loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_X29PU0xqtf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8d2e0375-606f-4df9-a6dd-294153840147"
      },
      "source": [
        "# print original weights for reference\n",
        "weights_original =  list(torch_model.parameters())\n",
        "weights_original"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.4179,  0.0135,  0.0296, -0.1518],\n",
              "         [ 0.3872, -0.1206, -0.4764,  0.3640],\n",
              "         [-0.0504,  0.3720, -0.3487,  0.2162],\n",
              "         [-0.0890,  0.4887,  0.2884,  0.3531],\n",
              "         [-0.0863,  0.2321,  0.3914, -0.3927],\n",
              "         [ 0.1562,  0.2368, -0.1866,  0.2092],\n",
              "         [-0.2788,  0.3466, -0.1761,  0.0908],\n",
              "         [ 0.0889,  0.4292, -0.4459,  0.1175]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3588, -0.1922, -0.1841, -0.3577,  0.4194, -0.0551, -0.2723, -0.4355],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0824, -0.0930, -0.0353,  0.2544, -0.0875, -0.2417, -0.0550, -0.2578],\n",
              "         [-0.0805, -0.0113,  0.1739,  0.1341,  0.0944, -0.0948, -0.3415,  0.1262],\n",
              "         [-0.0433,  0.1298, -0.1252, -0.0362,  0.0518, -0.2474, -0.3164, -0.2150]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0196,  0.3166, -0.1459], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWPjfxnBv8Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1: get your y_preds\n",
        "y_preds_torch = torch_model(X_train_tensor.float())\n",
        "\n",
        "# Step 2: Calculate your loss\n",
        "loss = torch_loss(y_preds_torch, y_train_tensor)\n",
        "\n",
        "# Step 3: Perform gradient descent using the built in method of PyTorch\n",
        "torch_model.zero_grad()\n",
        "loss.backward()\n",
        "\n",
        "# Step 4: Step your optimizer\n",
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fT-R0VnxGNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b708b588-f06c-4e81-e62f-154c7792b34b"
      },
      "source": [
        "# Check if your weights are updated by comparing this to what you printed above\n",
        "# when we printed 'weights_original'\n",
        "weights_new = list(torch_model.parameters())\n",
        "weights_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.4179,  0.0135,  0.0296, -0.1518],\n",
              "         [ 0.3882, -0.1216, -0.4754,  0.3650],\n",
              "         [-0.0514,  0.3710, -0.3497,  0.2152],\n",
              "         [-0.0900,  0.4877,  0.2874,  0.3521],\n",
              "         [-0.0853,  0.2311,  0.3924, -0.3917],\n",
              "         [ 0.1552,  0.2358, -0.1856,  0.2102],\n",
              "         [-0.2788,  0.3466, -0.1761,  0.0908],\n",
              "         [ 0.0879,  0.4282, -0.4469,  0.1165]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3588, -0.1912, -0.1851, -0.3587,  0.4184, -0.0561, -0.2723, -0.4365],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0824, -0.0920, -0.0343,  0.2534, -0.0885, -0.2407, -0.0550, -0.2568],\n",
              "         [-0.0805, -0.0123,  0.1729,  0.1331,  0.0934, -0.0958, -0.3415,  0.1252],\n",
              "         [-0.0433,  0.1288, -0.1262, -0.0352,  0.0528, -0.2464, -0.3164, -0.2160]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0206,  0.3156, -0.1449], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVgbIfTgrIO5",
        "colab_type": "text"
      },
      "source": [
        "# Now that we have a basic understanding let's train our model\n",
        "To do this you have to write your own loop to run epochs and batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8i4l0WPqXhu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "64e65adb-2277-4d1b-dfa2-d14387432b59"
      },
      "source": [
        "for epoch in range(50):\n",
        "  # Step 1: get your y_preds\n",
        "  y_preds_torch = torch_model(X_train_tensor.float())\n",
        "\n",
        "  # Step 2: Calculate your loss\n",
        "  loss = torch_loss(y_preds_torch, y_train_tensor)\n",
        "\n",
        "  # Step 3: Perform gradient descent using the built in method of PyTorch\n",
        "  torch_model.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  # Step 4: Step your optimizer\n",
        "  optimizer.step()\n",
        "  if epoch%10==0:\n",
        "    print(f\"Epoch {epoch} - loss: {loss}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - loss: 1.1460719108581543\n",
            "Epoch 10 - loss: 1.1351532936096191\n",
            "Epoch 20 - loss: 1.1250324249267578\n",
            "Epoch 30 - loss: 1.1159694194793701\n",
            "Epoch 40 - loss: 1.107917070388794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dkxx7b0d3uik",
        "colab_type": "text"
      },
      "source": [
        "## Let's get the accuracy score for our train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kx_VZogrWLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9544e962-14b7-409e-ae29-7e8f78184816"
      },
      "source": [
        "# get our train predictions\n",
        "y_train_torch_preds = torch_model(X_train_tensor.float())\n",
        "y_test_torch_preds = torch_model(X_test_tensor.float())\n",
        "y_train_torch_preds[:10] # print out the first ten rows of predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2529, 0.4146, 0.3325],\n",
              "        [0.2701, 0.4135, 0.3165],\n",
              "        [0.2604, 0.4164, 0.3232],\n",
              "        [0.2597, 0.4139, 0.3264],\n",
              "        [0.2568, 0.4254, 0.3178],\n",
              "        [0.2593, 0.4124, 0.3283],\n",
              "        [0.2629, 0.4160, 0.3211],\n",
              "        [0.2650, 0.4092, 0.3258],\n",
              "        [0.2447, 0.4143, 0.3411],\n",
              "        [0.2559, 0.4121, 0.3319]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nce33l5P3Jzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1752a9dc-e804-4b5e-b620-a7787990b31b"
      },
      "source": [
        "# convert our predictions into labels using the argmax function\n",
        "y_train_torch_labels = torch.argmax(y_train_torch_preds, axis=1)\n",
        "y_test_torch_labels = torch.argmax(y_test_torch_preds, axis=1)\n",
        "y_train_torch_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKKfXrav3LDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b83c83-048e-4c81-a51d-3ee2195e1afa"
      },
      "source": [
        "# score them using accuracy metric with the original y_train\n",
        "train_accuracy = torch.sum(y_train_tensor==y_train_torch_labels).float()/y_train_tensor.size()[0]\n",
        "test_accuracy = torch.sum(y_test_tensor==y_test_torch_labels).float()/y_test_tensor.size()[0]\n",
        "train_accuracy, test_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3386), tensor(0.3043))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl0xbge-6ucY",
        "colab_type": "text"
      },
      "source": [
        "# These scores are not that great...why? \n",
        "Well in our keras model we updated our weights with batches of 50, so how can we do that in our torch model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCugFdr84r--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0856e213-295b-4656-e204-b8ae0666daaf"
      },
      "source": [
        "BATCH_SIZE=50\n",
        "BATCHES = int(X_train_tensor.size()[0]/BATCH_SIZE) + 1 \n",
        "BATCHES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGJjraVd53Xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's do this again but with batches in our training process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt4dnqlB6Wk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instatiate a model\n",
        "torch_model_2 = nn.Sequential(\n",
        "    nn.Linear(4,  8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 3),\n",
        "    nn.Softmax(dim=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_DRCQcm86r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set your optimizer again and this time put in the same default parameters as the \n",
        "# Adam optimizer from Keras\n",
        "optimizer_2 = Adam_torch(torch_model_2.parameters(), lr=0.01, eps=1e-07, betas=[0.9, 0.999], amsgrad=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no5xd9ye7gFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "92213d21-df06-4903-c412-0b26891f1e22"
      },
      "source": [
        "# Print the weights\n",
        "weights = list(torch_model_2.parameters())\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.4661,  0.2455, -0.0401, -0.3149],\n",
              "         [ 0.0669,  0.0920,  0.4099,  0.0289],\n",
              "         [ 0.3300,  0.4426, -0.3211,  0.4648],\n",
              "         [ 0.0346, -0.4099,  0.0281, -0.0412],\n",
              "         [ 0.4326,  0.4621,  0.1303, -0.2941],\n",
              "         [-0.1068, -0.2049, -0.4479, -0.1129],\n",
              "         [-0.2391, -0.0022,  0.3952, -0.3517],\n",
              "         [ 0.1564, -0.3748, -0.2015,  0.0601]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.2731, -0.0801, -0.0281,  0.4276, -0.4954,  0.0574,  0.3185,  0.0614],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0965, -0.1093, -0.1519, -0.1744,  0.1534, -0.0845,  0.0024,  0.1230],\n",
              "         [-0.2349, -0.3046,  0.1011,  0.0566,  0.1607,  0.2407,  0.3435, -0.1156],\n",
              "         [-0.0148, -0.2547, -0.2807, -0.3118,  0.1278,  0.2637,  0.0572,  0.3393]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.2538, -0.2690, -0.2696], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHsgBETD7kj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3364746c-3094-4871-fdaf-8cc53c650afc"
      },
      "source": [
        "%timeit\n",
        "gradient_descent_counter = 0\n",
        "for epoch in range(50):\n",
        "  # we need to perform gradient descent in our batches loop!\n",
        "  for batch in range(BATCHES):\n",
        "    starting_index = batch*BATCH_SIZE \n",
        "    ending_index = (batch+1)*BATCH_SIZE \n",
        "    # because our batches don't evenly divide our row we need to do a try/except here\n",
        "    try:\n",
        "      X_train_batch = X_train_tensor[starting_index:ending_index]\n",
        "      y_train_batch = y_train_tensor[starting_index:ending_index]\n",
        "    except:\n",
        "      X_train_batch = X_train_tensor[starting_index:]\n",
        "      y_train_batch = y_train_tensor[starting_index:]\n",
        "    y_preds_torch = torch_model_2(X_train_batch.float())\n",
        "    loss = torch_loss(y_preds_torch, y_train_batch)\n",
        "    torch_model_2.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_2.step() \n",
        "    gradient_descent_counter += 1\n",
        "  if epoch%10==0:\n",
        "    print(f\"Epoch {epoch} - loss: {loss}\")\n",
        "\n",
        "print(f\"Gradient Descent Performed {gradient_descent_counter} times\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.48 µs\n",
            "Epoch 0 - loss: 1.1238813400268555\n",
            "Epoch 10 - loss: 0.9576315879821777\n",
            "Epoch 20 - loss: 0.8014950752258301\n",
            "Epoch 30 - loss: 0.6788737177848816\n",
            "Epoch 40 - loss: 0.6187527775764465\n",
            "Gradient Descent Performed 150 times\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faQr5dej8z-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def torch_scoring(model, X, y):\n",
        "  y_preds = model(X.float())\n",
        "  y_preds = torch.argmax(y_preds, axis=1)\n",
        "  score = torch.sum(y==y_preds).float()/y.size()[0]  \n",
        "  return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E1sUZmi9ncx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "374d80f2-174f-49d8-e873-d15ead125f97"
      },
      "source": [
        "train_score = torch_scoring(torch_model_2, X_train_tensor, y_train_tensor)\n",
        "test_score = torch_scoring(torch_model_2, X_test_tensor, y_test_tensor)\n",
        "train_score, test_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9764), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7_oGrAsB-bE",
        "colab_type": "text"
      },
      "source": [
        "# Let's compare the weights of our 2 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYaQcPTX_eIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18a10575-1d7b-4528-89ba-919386998009"
      },
      "source": [
        "for keras_layer, torch_layer in zip(model.weights, torch_model_2.parameters()):\n",
        "  print(\"Keras Layer\")\n",
        "  print(keras_layer.numpy().T)\n",
        "  print(\"PyTorch Layer\")\n",
        "  print(torch_layer)\n",
        "  print(\"Diffs\")\n",
        "  print(torch.tensor(keras_layer.numpy().T) - torch_layer)\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras Layer\n",
            "[[ 0.3996323   0.3691409  -0.500964    0.22652559]\n",
            " [ 0.14377505 -0.1819542  -0.37560984  0.36558813]\n",
            " [ 0.5485858  -0.43272293 -0.09885065  0.5367494 ]\n",
            " [ 0.21328695 -0.5406608   0.5270672  -0.35551763]\n",
            " [-0.67407614 -0.03242999  0.49590892  0.34737724]\n",
            " [ 0.47560582 -0.12535208  0.16390562  0.20797464]\n",
            " [ 0.11479455 -0.06462967 -0.51813376  0.6005848 ]\n",
            " [ 0.40960282  0.40233585  0.16305096 -0.43853295]]\n",
            "PyTorch Layer\n",
            "Parameter containing:\n",
            "tensor([[ 0.0221, -0.3198,  0.7998,  0.8409],\n",
            "        [ 0.3466,  0.5842, -0.7123, -0.9262],\n",
            "        [ 0.6306,  0.7011, -0.0882, -1.1945],\n",
            "        [ 0.7451,  0.4183, -0.8575, -0.5783],\n",
            "        [ 0.1850,  0.9270, -0.5356, -0.7872],\n",
            "        [ 0.2716,  0.2639, -0.1019,  0.2651],\n",
            "        [-0.4291,  0.1793,  0.7335,  1.1916],\n",
            "        [ 0.1464, -0.6341,  1.0616,  0.6809]], requires_grad=True)\n",
            "Diffs\n",
            "tensor([[ 0.3775,  0.6890, -1.3008, -0.6144],\n",
            "        [-0.2028, -0.7661,  0.3367,  1.2918],\n",
            "        [-0.0820, -1.1339, -0.0106,  1.7312],\n",
            "        [-0.5318, -0.9590,  1.3846,  0.2228],\n",
            "        [-0.8590, -0.9594,  1.0316,  1.1346],\n",
            "        [ 0.2040, -0.3892,  0.2658, -0.0572],\n",
            "        [ 0.5439, -0.2440, -1.2517, -0.5910],\n",
            "        [ 0.2632,  1.0364, -0.8986, -1.1195]], grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "\n",
            "Keras Layer\n",
            "[-0.12974787  0.         -0.07915567  0.15262951  0.         -0.11259035\n",
            "  0.         -0.10426002]\n",
            "PyTorch Layer\n",
            "Parameter containing:\n",
            "tensor([-0.2197,  0.3962,  1.0963,  0.1463,  1.1041, -0.1998, -0.4708, -0.2295],\n",
            "       requires_grad=True)\n",
            "Diffs\n",
            "tensor([ 0.0899, -0.3962, -1.1755,  0.0063, -1.1041,  0.0872,  0.4708,  0.1252],\n",
            "       grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "\n",
            "Keras Layer\n",
            "[[ 0.01868721  0.03690135  0.42924818 -0.6854205  -0.666668    0.374058\n",
            "  -0.68868464 -0.09407921]\n",
            " [ 0.05874521  0.2947666  -0.47405276  0.7419496   0.19978112  0.44494575\n",
            "   0.18627131 -0.12318089]\n",
            " [-0.593429    0.6584099  -0.04287222  0.61595666 -0.02241617  0.2653527\n",
            "   0.22252941 -0.25062793]]\n",
            "PyTorch Layer\n",
            "Parameter containing:\n",
            "tensor([[-0.3986,  0.2771,  0.2781,  0.9537,  0.3803,  0.0615, -0.9490, -0.7585],\n",
            "        [ 0.0128, -1.0854,  0.3362,  0.5621,  0.2200,  0.0790, -0.6625,  0.2715],\n",
            "        [ 0.4138, -0.4830, -0.6644, -1.0517, -1.3667, -0.0188,  0.9741,  0.7760]],\n",
            "       requires_grad=True)\n",
            "Diffs\n",
            "tensor([[ 0.4173, -0.2402,  0.1512, -1.6391, -1.0470,  0.3125,  0.2603,  0.6645],\n",
            "        [ 0.0459,  1.3801, -0.8102,  0.1798, -0.0202,  0.3659,  0.8488, -0.3947],\n",
            "        [-1.0072,  1.1414,  0.6215,  1.6676,  1.3443,  0.2842, -0.7516, -1.0266]],\n",
            "       grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "\n",
            "Keras Layer\n",
            "[-0.0988195   0.03113461  0.13845538]\n",
            "PyTorch Layer\n",
            "Parameter containing:\n",
            "tensor([ 0.5296,  0.5567, -0.4863], requires_grad=True)\n",
            "Diffs\n",
            "tensor([-0.6284, -0.5255,  0.6247], grad_fn=<SubBackward0>)\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2DzYtWrYZJj",
        "colab_type": "text"
      },
      "source": [
        "# Let's save each model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTpkqKpuYYhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from joblib import dump, load "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqE9IES3gryv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"lesson/\")\n",
        "os.mkdir(\"lesson/model/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqWJ39bfZFQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"./lesson/model/keras_model.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cY8LiiiZk3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(torch_model_2, \"./lesson/model/torch_model.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHj5m1TUZ6P_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bc738180-0fd6-4def-f932-91060672309b"
      },
      "source": [
        "!cd lesson/model && ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 44\n",
            "drwxr-xr-x 2 root root  4096 Jul  9 18:23 .\n",
            "drwxr-xr-x 3 root root  4096 Jul  9 18:23 ..\n",
            "-rw-r--r-- 1 root root 21288 Jul  9 18:23 keras_model.pkl\n",
            "-rw-r--r-- 1 root root  9766 Jul  9 18:23 torch_model.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hISXYuC5Z-Ub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "177b4c61-6a82-4896-b488-3b9f068e001d"
      },
      "source": [
        "%%timeit\n",
        "model_loaded = keras.models.load_model(\"./lesson/model/keras_model.pkl\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 378 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hKCNlZgadYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89cffab3-fae4-4c6d-f5c8-08ad4dc5cdcb"
      },
      "source": [
        "%%timeit\n",
        "torch_loaded = torch.load(\"./lesson/model/torch_model.pkl\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 6 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tfdyL2a1y3y",
        "colab_type": "text"
      },
      "source": [
        "# Viewing on tensorboard (WIP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXkSwvfU1t1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuCLqJU21tx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter(\"./lesson/runs/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMSKNTQF32Lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDAt1S8G1ttq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "26398f1c-be8b-4e2e-a662-ced2eef7992a"
      },
      "source": [
        "writer.add_graph(torch_model_2, X_train_tensor.float())\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZQO9SY30e7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir=\"./lesson/runs/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_AOd7bt5Von",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}